# ğŸ‡°ğŸ‡· Policy LLM Fine-Tuning with LoRA (Polyglot-ko-1.3B)

ì´ í”„ë¡œì íŠ¸ëŠ” í•œêµ­ì˜ êµ­ê°€ ê³¼í•™ê¸°ìˆ  ì •ì±… ì–¸ì–´ì— íŠ¹í™”ëœ ì§ˆì˜ì‘ë‹µ ì–¸ì–´ëª¨ë¸ì„ ê°œë°œí•˜ê¸° ìœ„í•´, Polyglot-ko-1.3B ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ **LoRA (Low-Rank Adaptation)** íŒŒì¸íŠœë‹ ê¸°ë²•ì„ ì ìš©í•œ ì‹¤í—˜ì…ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ëŠ” ã€Œì œ3ì°¨ êµ­ê°€ì´ˆê³ ì„±ëŠ¥ì»´í“¨íŒ… ìœ¡ì„± ê¸°ë³¸ê³„íš (2023~2027)ã€ ë¬¸ì„œë¥¼ instruction í˜•ì‹ìœ¼ë¡œ ê°€ê³µí•˜ì—¬ êµ¬ì„±ë˜ì—ˆìœ¼ë©°, íŒŒì¸íŠœë‹ ì´í›„ BLEU, ROUGE, ì •ì±… í‚¤ì›Œë“œ ë°˜ì˜ë¥  ë“± ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì„±ëŠ¥ì„ í‰ê°€í•˜ì˜€ìŠµë‹ˆë‹¤.

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

policy-llm-lora-finetuning/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # ì›ë³¸ ì •ì±… ë¬¸ì„œ
â”‚ â””â”€â”€ processed/ # ì „ì²˜ë¦¬ëœ instruction í¬ë§· í•™ìŠµ ë°ì´í„°
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ prepare_dataset.py # ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
â”‚ â”œâ”€â”€ run_finetune.py # LoRA ê¸°ë°˜ íŒŒì¸íŠœë‹ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚ â”œâ”€â”€ eval_compare.py # íŠœë‹ ì „í›„ ì‘ë‹µ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”‚ â””â”€â”€ config/ # (ì˜µì…˜) ì„¤ì • json íŒŒì¼ ë“±
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ koni-lora-checkpoint/ # í•™ìŠµëœ adapter ê²°ê³¼
â”‚ â””â”€â”€ response_outputs/ # íŠœë‹ ì „í›„ ê²°ê³¼ íŒŒì¼
â”‚
â””â”€â”€ notebooks/
â””â”€â”€ exploratory_analysis.ipynb # ì •ëŸ‰ ë° ì •ì„± í‰ê°€ ë…¸íŠ¸ë¶

yaml
ë³µì‚¬
í¸ì§‘

---

## ğŸš€ ì½”ë“œ ì‹¤í–‰ ì˜ˆì‹œ

### 1. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install -r requirements.txt
2. ë°ì´í„° ì „ì²˜ë¦¬
bash
ë³µì‚¬
í¸ì§‘
python src/prepare_dataset.py \
  --input data/raw/policy_source.txt \
  --output data/processed/koni_finetune_sntp_sample.csv
3. LoRA ê¸°ë°˜ íŒŒì¸íŠœë‹ ì‹¤í–‰
bash
ë³µì‚¬
í¸ì§‘
python src/run_finetune.py \
  --base_model EleutherAI/polyglot-ko-1.3b \
  --data_path data/processed/koni_finetune_sntp_sample.csv \
  --output_dir outputs/koni-lora-checkpoint
4. íŠœë‹ ì „í›„ ì‘ë‹µ ë¹„êµ ë° í‰ê°€
bash
ë³µì‚¬
í¸ì§‘
python src/eval_compare.py \
  --questions_file data/processed/eval_questions.txt \
  --model_paths EleutherAI/polyglot-ko-1.3b outputs/koni-lora-checkpoint
ğŸ§¾ ë°ì´í„° ì¶œì²˜
í•™ìŠµ ë°ì´í„°ëŠ” ã€Œì œ3ì°¨ êµ­ê°€ì´ˆê³ ì„±ëŠ¥ì»´í“¨íŒ… ìœ¡ì„± ê¸°ë³¸ê³„íš(2023~2027)ã€ ì›ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì‘ì—…ìœ¼ë¡œ instruction í˜•ì‹ (instruction, input, output)ìœ¼ë¡œ ê°€ê³µí•˜ì˜€ìŠµë‹ˆë‹¤.

í•´ë‹¹ ë¬¸ì„œëŠ” ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€ê°€ ê³µê°œí•œ ê³µê³µ ì •ì±… ë¬¸ì„œë¡œ, ì¶œì²˜ëŠ” êµ­ê°€ê³¼í•™ê¸°ìˆ ì§€ì‹ì •ë³´ì„œë¹„ìŠ¤(NTIS) ë“±ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í‰ê°€ìš© ì§ˆë¬¸ì€ ì‹¤ì œ ê³¼í•™ê¸°ìˆ  ì •ì±… ì˜ì—­ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” í•µì‹¬ ìŸì ì„ ë°”íƒ•ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ§  ì‚¬ìš© ëª¨ë¸ ì •ë³´
í•­ëª©	ì •ë³´
ê¸°ë°˜ ëª¨ë¸	EleutherAI/polyglot-ko-1.3b
íŠœë‹ ê¸°ë²•	LoRA (Low-Rank Adaptation) with Huggingface PEFT
í•™ìŠµ í™˜ê²½	Google Colab (T4 / A100 GPU í™˜ê²½)
íŠœë‹ ëª©ì 	ì •ì±… ì§ˆì˜ì‘ë‹µì˜ ì •ë³´ ë°˜ì˜ë ¥ ë° ì–¸ì–´ í’ˆì§ˆ í–¥ìƒ
ì¶œë ¥ í˜•ì‹	adapter_config.json, adapter_model.safetensors

ğŸ“Š í‰ê°€ ì§€í‘œ
BLEU / ROUGE-L: ì •ì±… ì‘ë‹µ ì •ëŸ‰ì  ì •í™•ë„

ì •ì„± í‰ê°€: ì˜¤ë¥˜ ìœ í˜• ë¶„ë¥˜ (ì •ë³´ ëˆ„ë½, ì •ì±… ê¸°ê´€ ì˜¤ìš© ë“±)

ì •ì±… í‚¤ì›Œë“œ ë°˜ì˜ë¥ : í•µì‹¬ ìš©ì–´ í¬í•¨ ë¹„ìœ¨

ì§ˆë¬¸ ìœ í˜•ë³„ ì„±ëŠ¥ ë¹„êµ: ë²•ë ¹/ê¸°ê´€/ì‚°ì—…/ì¶”ë¡  ë“± ë¶„ë¥˜ ê¸°ì¤€ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”

ğŸ“š ì°¸ê³  ë¬¸í—Œ
Hu et al. (2021). LoRA: Low-Rank Adaptation of Large Language Models

Caudron et al. (2024). Adaptation of LLMs for the Public Sector

Ren et al. (2025). AT-RAFT for Research Policy Interpretation

Sun et al. (2024). Instruction-Tuning for Policy Text Classification
